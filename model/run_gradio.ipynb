{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate -U\n",
    "!pip install pandas\n",
    "!pip install datasets\n",
    "!pip install konlpy\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install konlpy\n",
    "!pip install gradio==3.50\n",
    "!pip install scikit-learn\n",
    "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
    "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
    "%cd Mecab-ko-for-Google-Colab/\n",
    "!bash install_mecab-ko_on_colab_light_220429.sh\n",
    "%cd ../\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Mecab\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, ElectraForSequenceClassification, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import gradio as gr\n",
    "from gradio.mix import Parallel\n",
    "import torch.nn as nn\n",
    "from kobert_tokenizer import KoBERTTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio 단수모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bb(text):\n",
    "    # 카테고리 정의\n",
    "    categories = ['정치', '경제', '사회', '국제']\n",
    "\n",
    "    # 텍스트를 Mecab으로 토크나이징합니다.\n",
    "    mecab = Mecab()\n",
    "    tokens = mecab.morphs(text)\n",
    "\n",
    "    # 사전 훈련된 모델 로드\n",
    "    model_name = \"bert-base-multilingual-cased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 토크나이징된 텍스트를 Hugging Face의 토크나이저에 전달합니다.\n",
    "    inputs = tokenizer(' '.join(tokens), padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "    # 사전 훈련된 모델 로드\n",
    "    model_multilingual = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(device)\n",
    "\n",
    "    # 체크포인트 로드\n",
    "    checkpoint_path = \"/home/kannakawai9/sessac_project/epochs_3_t_v_t.pt\"\n",
    "    model_multilingual.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # 모델을 평가 모드로 설정합니다.\n",
    "    model_multilingual.eval()\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    with torch.no_grad():\n",
    "        outputs = model_multilingual(**inputs)\n",
    "\n",
    "    # 출력에서 가장 높은 값을 가진 클래스를 찾습니다.\n",
    "    _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "    # 예측된 클래스를 해당하는 카테고리 이름으로 변환합니다.\n",
    "    category = categories[predicted.item()]\n",
    "\n",
    "    return category\n",
    "\n",
    "# Gradio 인터페이스를 생성합니다.\n",
    "iface = gr.Interface(\n",
    "    fn=predict_bb,  # 사용할 함수\n",
    "    inputs=\"text\",    # 입력 타입\n",
    "    outputs=\"text\"    # 출력 타입\n",
    ")\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kl(text):\n",
    "    # 사전 훈련된 모델 로드\n",
    "    model = ElectraForSequenceClassification.from_pretrained(\"copycats/koelectra-base-v3-generalized-sentiment-analysis\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"copycats/koelectra-base-v3-generalized-sentiment-analysis\")\n",
    "\n",
    "    # classifier의 out_proj 레이어의 출력 차원을 4(레이블 수)로 조정\n",
    "    model.classifier.out_proj = nn.Linear(in_features=model.classifier.dense.out_features, out_features=4)\n",
    "\n",
    "    # 모델의 num_labels 속성 업데이트\n",
    "    model.num_labels = 4\n",
    "\n",
    "    # 체크포인트 로드\n",
    "    checkpoint_path = \"/home/kannakawai9/best_not_one_koelectra12.pt\"\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # 레이블 딕셔너리 정의\n",
    "    label_dict = {'정치': 0, '사회': 1, '경제': 2, '국제': 3}\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    categories = ['정치', '사회', '경제', '국제']\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    # 텍스트를 Mecab으로 토크나이징합니다.\n",
    "    tokens = mecab.morphs(text)\n",
    "\n",
    "    # 토크나이징된 텍스트를 Hugging Face의 토크나이저에 전달합니다.\n",
    "    inputs = tokenizer(' '.join(tokens), padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "    # 모델을 평가 모드로 설정합니다.\n",
    "    model.eval()\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 출력에서 가장 높은 값을 가진 클래스를 찾습니다.\n",
    "    _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "    # 예측된 클래스를 해당하는 카테고리 이름으로 변환합니다.\n",
    "    category = categories[predicted.item()]\n",
    "\n",
    "    return category\n",
    "\n",
    "# Gradio 인터페이스를 생성합니다.\n",
    "iface = gr.Interface(\n",
    "    fn=predict_kl,  # 사용할 함수\n",
    "    inputs=\"text\",    # 입력 타입\n",
    "    outputs=\"text\"    # 출력 타입\n",
    ")\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "iface.launch(share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kb(text):\n",
    "    # 사전 훈련된 모델 로드\n",
    "    model = BertModel.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "    # CustomModel 정의\n",
    "    class CustomModel(nn.Module):\n",
    "        def __init__(self, model, num_classes):\n",
    "            super(CustomModel, self).__init__() # 부모 클래스 초기화\n",
    "            self.bert = model\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "            self.fc = nn.Linear(768, num_classes)\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "            output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            last_hidden_state = output['last_hidden_state']\n",
    "            output = self.dropout(last_hidden_state[:, 0, :])\n",
    "            output = self.fc(output)\n",
    "            return output\n",
    "\n",
    "    # CustomModel 인스턴스 생성\n",
    "    model = CustomModel(model, num_classes=4)\n",
    "\n",
    "    # 체크포인트 로드\n",
    "    checkpoint_path = \"/home/kannakawai9/sessac_project/kobert.pt\"\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # 사전 훈련된 모델 로드\n",
    "    tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "    # 레이블 딕셔너리 정의\n",
    "    label_dict = {0: '정치', 1: '사회', 2: '경제', 3: '국제'}\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    categories = ['정치', '사회', '경제', '국제']\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    # 텍스트를 Mecab으로 토크나이징합니다.\n",
    "    tokens = mecab.morphs(text)\n",
    "\n",
    "    # 토크나이징된 텍스트를 Hugging Face의 토크나이저에 전달합니다.\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        ' '.join(tokens),\n",
    "        return_tensors='pt',     # 텐서로 반환\n",
    "        truncation=True,         # 입력 시퀀스가 최대 길이를 초과할 때 자를지 여부 결정\n",
    "        padding='max_length',\n",
    "        max_length=512, # 최대 입력 길이\n",
    "        add_special_tokens=True\n",
    "    )\n",
    "    inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "\n",
    "    # 모델을 평가 모드로 설정합니다.\n",
    "    model.eval()\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 출력에서 가장 높은 값을 가진 클래스를 찾습니다.\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # 예측된 클래스를 해당하는 카테고리 이름으로 변환합니다.\n",
    "    category = categories[predicted.item()]\n",
    "\n",
    "    return category\n",
    "\n",
    "# Gradio 인터페이스를 생성합니다.\n",
    "iface = gr.Interface(\n",
    "    fn=predict_kb,  # 사용할 함수\n",
    "    inputs=\"text\",    # 입력 타입\n",
    "    outputs=\"text\"    # 출력 타입\n",
    ")\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kr(text):\n",
    "    # 사전 훈련된 모델 로드\n",
    "    model = ElectraForSequenceClassification.from_pretrained(\"klue/roberta-base\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"klue/roberta-base\")\n",
    "\n",
    "    # classifier의 out_proj 레이어의 출력 차원을 4(레이블 수)로 조정\n",
    "    model.classifier.out_proj = nn.Linear(in_features=model.classifier.dense.out_features, out_features=4)\n",
    "\n",
    "    # 모델의 num_labels 속성 업데이트\n",
    "    model.num_labels = 4\n",
    "\n",
    "    # 체크포인트 로드\n",
    "    checkpoint_path = \"/home/kannakawai9/klue_roberta.pt\"\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    # 레이블 딕셔너리 정의\n",
    "    label_dict = {0: '정치', 1: '사회', 2: '경제', 3: '국제'}\n",
    "\n",
    "    # 디바이스 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    categories = ['정치', '사회', '경제', '국제']\n",
    "    mecab = Mecab()\n",
    "    \n",
    "    # 텍스트를 Mecab으로 토크나이징합니다.\n",
    "    tokens = mecab.morphs(text)\n",
    "\n",
    "    # 토크나이징된 텍스트를 Hugging Face의 토크나이저에 전달합니다.\n",
    "    inputs = tokenizer(' '.join(tokens), padding=True, truncation=True, max_length=512, return_tensors='pt').to(device)\n",
    "\n",
    "    # 모델을 평가 모드로 설정합니다.\n",
    "    model.eval()\n",
    "\n",
    "    # 예측을 수행합니다.\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # 출력에서 가장 높은 값을 가진 클래스를 찾습니다.\n",
    "    _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "    # 예측된 클래스를 해당하는 카테고리 이름으로 변환합니다.\n",
    "    category = categories[predicted.item()]\n",
    "\n",
    "    return category\n",
    "\n",
    "# Gradio 인터페이스를 생성합니다.\n",
    "iface = gr.Interface(\n",
    "    fn=predict_kr,  # 사용할 함수\n",
    "    inputs=\"text\",    # 입력 타입\n",
    "    outputs=\"text\"    # 출력 타입\n",
    ")\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "iface.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradio 복수 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iface_bb = gr.Interface(fn=predict_bb, inputs=\"textbox\", outputs=[gr.Textbox(label=\"bert-base-multilingual-cased\", lines=3)])\n",
    "iface_kl = gr.Interface(fn=predict_kl, inputs=\"textbox\", outputs=[gr.Textbox(label=\"copycats/koelectra-base-v3-generalized-sentiment-analysis\", lines=3)])\n",
    "iface_kb = gr.Interface(fn=predict_kb, inputs=\"textbox\", outputs=[gr.Textbox(label=\"skt/kobert-base-v1\", lines=3)])\n",
    "iface_kr = gr.Interface(fn=predict_kr, inputs=\"textbox\", outputs=[gr.Textbox(label=\"klue/roberta-base\", lines=3)])\n",
    "\n",
    "# Parallel 인터페이스를 정의합니다.\n",
    "iface = Parallel(iface_bb, iface_kl, iface_kb, iface_kr)\n",
    "\n",
    "# Gradio 인터페이스를 실행합니다.\n",
    "iface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
